{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Comment Rate in the ... Validation Set\n",
      "* Whole: 0.7341818181818182\n",
      "* Female: 0.7381429525718103\n",
      "* Male: 0.7257254464285714\n"
     ]
    }
   ],
   "source": [
    "# Import the library\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def preprocess(path):\n",
    "    \"\"\"Read and preprocess the data\"\"\"\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Raw data\n",
    "train_raw = preprocess(\"data/TRAIN.csv\")\n",
    "valid_raw = preprocess(\"data/VALIDATION.csv\")\n",
    "# test_raw = preprocess(\"data/TEST_NO_LABELS.csv\")\n",
    "\n",
    "# TFIDF\n",
    "train_X = preprocess(\"data/TFIDF_TRAIN.csv\")\n",
    "valid_X = preprocess(\"data/TFIDF_VALIDATION.csv\")\n",
    "# test_X = preprocess(\"data/TFIDF_TEST.csv\")\n",
    "\n",
    "\n",
    "def partition_vert(df):\n",
    "    \"\"\"Partition the dataset into features and labels\"\"\"\n",
    "\n",
    "    X = df.iloc[:, 1:-1]\n",
    "    y_i = df.iloc[:, -1]\n",
    "    return X, y_i\n",
    "\n",
    "\n",
    "# Obtain the true labels\n",
    "_, train_y_true = partition_vert(train_raw)\n",
    "_, valid_y_true = partition_vert(valid_raw)\n",
    "\n",
    "\n",
    "def split_by_gender(df):\n",
    "    \"\"\"Split the data frame based on gender\"\"\"\n",
    "\n",
    "    female_samples = df[df[\"dr_id_gender\"] == 0]\n",
    "    male_samples = df[df[\"dr_id_gender\"] == 1]\n",
    "    ungendered_samples = df[df[\"dr_id_gender\"] == 2]\n",
    "\n",
    "    return female_samples, male_samples, ungendered_samples\n",
    "\n",
    "\n",
    "# Partition datasets vertically and horizontally by gender\n",
    "train_raw_with_id = train_raw.reset_index()\n",
    "valid_raw_with_id = valid_raw.reset_index()\n",
    "train_X_with_id = train_X.reset_index()\n",
    "valid_X_with_id = valid_X.reset_index()\n",
    "\n",
    "train_raw_female, train_raw_male, _ = split_by_gender(train_raw_with_id)\n",
    "valid_raw_female, valid_raw_male, _ = split_by_gender(valid_raw_with_id)\n",
    "\n",
    "_, train_y_true_female = partition_vert(train_raw_female)\n",
    "_, valid_y_true_female = partition_vert(valid_raw_female)\n",
    "train_X_female = train_X_with_id[train_raw_with_id[\"dr_id_gender\"]\n",
    "                                 == 0].iloc[:, 1:]\n",
    "valid_X_female = valid_X_with_id[valid_raw_with_id[\"dr_id_gender\"]\n",
    "                                 == 0].iloc[:, 1:]\n",
    "\n",
    "_, train_y_true_male = partition_vert(train_raw_male)\n",
    "_, valid_y_true_male = partition_vert(valid_raw_male)\n",
    "train_X_male = train_X_with_id[train_raw_with_id[\"dr_id_gender\"]\n",
    "                               == 1].iloc[:, 1:]\n",
    "valid_X_male = valid_X_with_id[valid_raw_with_id[\"dr_id_gender\"]\n",
    "                               == 1].iloc[:, 1:]\n",
    "\n",
    "\n",
    "def cal_pos_comment_dist(df):\n",
    "    \"\"\"Calculate the distribution of the positive comments\"\"\"\n",
    "\n",
    "    pos_comment_count = len(df[df[\"rating\"] == 1])\n",
    "    neg_comment_count = len(df[df[\"rating\"] == -1])\n",
    "\n",
    "    return pos_comment_count / (pos_comment_count + neg_comment_count)\n",
    "\n",
    "\n",
    "print(\"Positive Comment Rate in the ... Validation Set\")\n",
    "print(\"* Whole: \" + str(cal_pos_comment_dist(valid_raw)))\n",
    "print(\"* Female: \" + str(cal_pos_comment_dist(valid_raw_female)))\n",
    "print(\"* Male: \" + str(cal_pos_comment_dist(valid_raw_male)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZeroR Baseline > Whole Validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00      1462\n",
      "           1       0.73      1.00      0.85      4038\n",
      "\n",
      "    accuracy                           0.73      5500\n",
      "   macro avg       0.37      0.50      0.42      5500\n",
      "weighted avg       0.54      0.73      0.62      5500\n",
      "\n",
      "\n",
      "ZeroR Baseline > Female Validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       392\n",
      "           1       0.74      1.00      0.85      1105\n",
      "\n",
      "    accuracy                           0.74      1497\n",
      "   macro avg       0.37      0.50      0.42      1497\n",
      "weighted avg       0.54      0.74      0.63      1497\n",
      "\n",
      "\n",
      "ZeroR Baseline > Male Validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       983\n",
      "           1       0.73      1.00      0.84      2601\n",
      "\n",
      "    accuracy                           0.73      3584\n",
      "   macro avg       0.36      0.50      0.42      3584\n",
      "weighted avg       0.53      0.73      0.61      3584\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the library for baseline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "\n",
    "def zero_R_classify(training_feat, training_label, valid_feat, valid_label_true):\n",
    "    \"\"\"Define the ZeroR classifier\"\"\"\n",
    "\n",
    "    # Implement the ZeroR classifier\n",
    "    ZeroR_clf = DummyClassifier(strategy=\"most_frequent\", random_state=42)\n",
    "    ZeroR_clf.fit(X=training_feat, y=training_label)\n",
    "    valid_y_pred = ZeroR_clf.predict(X=valid_feat)\n",
    "\n",
    "    # Show evaluation results\n",
    "    print(classification_report(y_true=valid_label_true,\n",
    "          y_pred=valid_y_pred, zero_division=0.0))\n",
    "    print()\n",
    "\n",
    "\n",
    "print(\"ZeroR Baseline > Whole Validation set\")\n",
    "zero_R_classify(train_X, train_y_true, valid_X, valid_y_true)\n",
    "\n",
    "print(\"ZeroR Baseline > Female Validation set\")\n",
    "zero_R_classify(train_X_female, train_y_true_female,\n",
    "                valid_X_female, valid_y_true_female)\n",
    "\n",
    "print(\"ZeroR Baseline > Male Validation set\")\n",
    "zero_R_classify(train_X_male, train_y_true_male,\n",
    "                valid_X_male, valid_y_true_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN > Whole Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.71      0.61      0.66      1462\n",
      "           1       0.87      0.91      0.89      4038\n",
      "\n",
      "    accuracy                           0.83      5500\n",
      "   macro avg       0.79      0.76      0.77      5500\n",
      "weighted avg       0.82      0.83      0.83      5500\n",
      "\n",
      "KNN > Female Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.71      0.64      0.68       392\n",
      "           1       0.88      0.91      0.89      1105\n",
      "\n",
      "    accuracy                           0.84      1497\n",
      "   macro avg       0.79      0.78      0.78      1497\n",
      "weighted avg       0.83      0.84      0.84      1497\n",
      "\n",
      "KNN > Male Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.65      0.69       983\n",
      "           1       0.87      0.91      0.89      2601\n",
      "\n",
      "    accuracy                           0.84      3584\n",
      "   macro avg       0.80      0.78      0.79      3584\n",
      "weighted avg       0.83      0.84      0.84      3584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the library for KNN classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "def knn_classify(training_feat, training_label, valid_feat, valid_label_true):\n",
    "    \"\"\"Define the KNN classifier\"\"\"\n",
    "\n",
    "    # Implement the KNN classifier for TF-IDF\n",
    "    KNNclf = KNeighborsClassifier(weights=\"distance\", metric=\"cosine\")\n",
    "    KNNclf.fit(X=training_feat, y=training_label)\n",
    "    valid_label_pred = KNNclf.predict(X=valid_feat)\n",
    "\n",
    "    # Show evaluation results\n",
    "    print(classification_report(y_true=valid_label_true, y_pred=valid_label_pred))\n",
    "\n",
    "\n",
    "print(\"KNN > Whole Validation Set\")\n",
    "knn_classify(train_X, train_y_true, valid_X, valid_y_true)\n",
    "\n",
    "print(\"KNN > Female Validation Set\")\n",
    "knn_classify(train_X_female, train_y_true_female,\n",
    "             valid_X_female, valid_y_true_female)\n",
    "\n",
    "print(\"KNN > Male Validation Set\")\n",
    "knn_classify(train_X_male, train_y_true_male, valid_X_male, valid_y_true_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB > Whole Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.66      0.75      1462\n",
      "           1       0.89      0.97      0.93      4038\n",
      "\n",
      "    accuracy                           0.89      5500\n",
      "   macro avg       0.88      0.81      0.84      5500\n",
      "weighted avg       0.88      0.89      0.88      5500\n",
      "\n",
      "NB > Female Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.83      0.74      0.78       392\n",
      "           1       0.91      0.94      0.93      1105\n",
      "\n",
      "    accuracy                           0.89      1497\n",
      "   macro avg       0.87      0.84      0.85      1497\n",
      "weighted avg       0.89      0.89      0.89      1497\n",
      "\n",
      "NB > Male Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.66      0.76       983\n",
      "           1       0.88      0.97      0.92      2601\n",
      "\n",
      "    accuracy                           0.88      3584\n",
      "   macro avg       0.89      0.81      0.84      3584\n",
      "weighted avg       0.89      0.88      0.88      3584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the library for the MultinomialNB classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "def nb_classify(training_feat, training_label, valid_feat, valid_label_true):\n",
    "    \"\"\"Define the naive Bayesian classifier\"\"\"\n",
    "\n",
    "    # Implement the MultinomialNB classifier for TF-IDF\n",
    "    NBclf = MultinomialNB(alpha=0.001)\n",
    "    NBclf.fit(X=training_feat, y=training_label)\n",
    "    valid_label_pred = NBclf.predict(X=valid_feat)\n",
    "\n",
    "    # Show evaluation results\n",
    "    print(classification_report(y_true=valid_label_true, y_pred=valid_label_pred))\n",
    "\n",
    "\n",
    "print(\"NB > Whole Validation Set\")\n",
    "nb_classify(train_X, train_y_true, valid_X, valid_y_true)\n",
    "\n",
    "print(\"NB > Female Validation Set\")\n",
    "nb_classify(train_X_female, train_y_true_female,\n",
    "            valid_X_female, valid_y_true_female)\n",
    "\n",
    "print(\"NB > Male Validation Set\")\n",
    "nb_classify(train_X_male, train_y_true_male, valid_X_male, valid_y_true_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR > Whole Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.84      0.83      1462\n",
      "           1       0.94      0.93      0.94      4038\n",
      "\n",
      "    accuracy                           0.91      5500\n",
      "   macro avg       0.88      0.89      0.88      5500\n",
      "weighted avg       0.91      0.91      0.91      5500\n",
      "\n",
      "LR > Female Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.85      0.84       392\n",
      "           1       0.95      0.94      0.94      1105\n",
      "\n",
      "    accuracy                           0.92      1497\n",
      "   macro avg       0.89      0.90      0.89      1497\n",
      "weighted avg       0.92      0.92      0.92      1497\n",
      "\n",
      "LR > Male Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.84      0.84       983\n",
      "           1       0.94      0.94      0.94      2601\n",
      "\n",
      "    accuracy                           0.91      3584\n",
      "   macro avg       0.89      0.89      0.89      3584\n",
      "weighted avg       0.91      0.91      0.91      3584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the library for logistic regressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def lr_classify(training_feat, training_label, valid_feat, valid_label_true):\n",
    "    \"\"\"Define the logistic regression classifier\"\"\"\n",
    "\n",
    "    # Implements the logistic regressor for TF-IDF\n",
    "    LRclf = LogisticRegression(max_iter=1_000, random_state=42)\n",
    "    LRclf.fit(X=training_feat, y=training_label)\n",
    "    valid_label_pred = LRclf.predict(X=valid_feat)\n",
    "\n",
    "    # Shows evaluation results\n",
    "    print(classification_report(y_true=valid_label_true, y_pred=valid_label_pred))\n",
    "\n",
    "\n",
    "print(\"LR > Whole Validation Set\")\n",
    "lr_classify(train_X, train_y_true, valid_X, valid_y_true)\n",
    "\n",
    "print(\"LR > Female Validation Set\")\n",
    "lr_classify(train_X_female, train_y_true_female,\n",
    "            valid_X_female, valid_y_true_female)\n",
    "\n",
    "print(\"LR > Male Validation Set\")\n",
    "lr_classify(train_X_male, train_y_true_male, valid_X_male, valid_y_true_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP > Whole Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.80      0.85      0.83      1462\n",
      "           1       0.94      0.92      0.93      4038\n",
      "\n",
      "    accuracy                           0.90      5500\n",
      "   macro avg       0.87      0.89      0.88      5500\n",
      "weighted avg       0.91      0.90      0.91      5500\n",
      "\n",
      "MLP > Female Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.85      0.83       392\n",
      "           1       0.95      0.93      0.94      1105\n",
      "\n",
      "    accuracy                           0.91      1497\n",
      "   macro avg       0.88      0.89      0.88      1497\n",
      "weighted avg       0.91      0.91      0.91      1497\n",
      "\n",
      "MLP > Male Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.84      0.84       983\n",
      "           1       0.94      0.94      0.94      2601\n",
      "\n",
      "    accuracy                           0.91      3584\n",
      "   macro avg       0.89      0.89      0.89      3584\n",
      "weighted avg       0.91      0.91      0.91      3584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the library for the MLP classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "def mlp_classify(training_feat, training_label, valid_feat, valid_label_true):\n",
    "    \"\"\"Define the MLP classifier\"\"\"\n",
    "\n",
    "    # Implement the MLP classifier for TF-IDF\n",
    "    MLPclf = MLPClassifier(activation=\"logistic\",\n",
    "                           max_iter=1_000, random_state=42)\n",
    "    MLPclf.fit(X=training_feat, y=training_label)\n",
    "    valid_label_pred = MLPclf.predict(X=valid_feat)\n",
    "\n",
    "    # Show evaluation results\n",
    "    print(classification_report(y_true=valid_label_true, y_pred=valid_label_pred))\n",
    "\n",
    "\n",
    "print(\"MLP > Whole Validation Set\")\n",
    "mlp_classify(train_X, train_y_true, valid_X, valid_y_true)\n",
    "\n",
    "print(\"MLP > Female Validation Set\")\n",
    "mlp_classify(train_X_female, train_y_true_female,\n",
    "             valid_X_female, valid_y_true_female)\n",
    "\n",
    "print(\"MLP > Male Validation Set\")\n",
    "mlp_classify(train_X_male, train_y_true_male, valid_X_male, valid_y_true_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing Genders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_gender_on_datasets(raw_df, tfidf_df):\n",
    "    female_samples = raw_df[raw_df[\"dr_id_gender\"] == 0]\n",
    "    male_samples = raw_df[raw_df[\"dr_id_gender\"] == 1]\n",
    "\n",
    "    min_samples = min(len(female_samples), len(male_samples))\n",
    "    balanced_female_samples = female_samples.sample(\n",
    "        n=min_samples, random_state=42)\n",
    "    balanced_male_samples = male_samples.sample(n=min_samples, random_state=42)\n",
    "\n",
    "    # Concatenate balanced samples\n",
    "    balanced_raw = pd.concat([balanced_female_samples, balanced_male_samples])\n",
    "\n",
    "    # Find corresponding rows in train_X\n",
    "    balanced_X = tfidf_df[tfidf_df.index.isin(balanced_raw.index)]\n",
    "\n",
    "    return balanced_raw, balanced_X\n",
    "\n",
    "\n",
    "# Raw data\n",
    "train_raw = pd.read_csv(\"data/TRAIN.csv\")\n",
    "valid_raw = pd.read_csv(\"data/VALIDATION.csv\")\n",
    "# test_raw = pd.read_csv(\"data/TEST_NO_LABELS.csv\")\n",
    "\n",
    "# TFIDF\n",
    "train_X = pd.read_csv(\"data/TFIDF_TRAIN.csv\")\n",
    "valid_X = pd.read_csv(\"data/TFIDF_VALIDATION.csv\")\n",
    "# test_X = pd.read_csv(\"data/TFIDF_TEST.csv\")\n",
    "\n",
    "# Balance the datasets by gender\n",
    "train_raw, train_X = balance_gender_on_datasets(train_raw, train_X)\n",
    "valid_raw, valid_X = balance_gender_on_datasets(valid_raw, valid_X)\n",
    "\n",
    "train_raw = train_raw.sort_values(by=\"Unnamed: 0\")\n",
    "train_X = train_X.sort_values(by=\"Unnamed: 0\")\n",
    "valid_raw = valid_raw.sort_values(by=\"Unnamed: 0\")\n",
    "valid_X = valid_X.sort_values(by=\"Unnamed: 0\")\n",
    "\n",
    "# Obtain the true labels\n",
    "train_y_true = train_raw.iloc[:, -1]\n",
    "valid_y_true = valid_raw.iloc[:, -1]\n",
    "\n",
    "# Split the set by gender\n",
    "train_raw_female, train_raw_male, _ = split_by_gender(train_raw)\n",
    "valid_raw_female, valid_raw_male, _ = split_by_gender(valid_raw)\n",
    "\n",
    "train_y_true_female = train_raw_female.iloc[:, -1]\n",
    "valid_y_true_female = valid_raw_female.iloc[:, -1]\n",
    "train_X_female = train_X[train_raw[\"dr_id_gender\"] == 0]\n",
    "valid_X_female = valid_X[valid_raw[\"dr_id_gender\"] == 0]\n",
    "\n",
    "train_y_true_male = train_raw_male.iloc[:, -1]\n",
    "valid_y_true_male = valid_raw_male.iloc[:, -1]\n",
    "train_X_male = train_X[train_raw[\"dr_id_gender\"] == 1]\n",
    "valid_X_male = valid_X[valid_raw[\"dr_id_gender\"] == 1]\n",
    "\n",
    "# Remove the index\n",
    "\n",
    "\n",
    "def remove_index(df):\n",
    "    if \"Unnamed: 0\" in df.columns:\n",
    "        df = df.copy()\n",
    "        df.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "train_X = remove_index(train_X)\n",
    "train_X_female = remove_index(train_X_female)\n",
    "train_X_male = remove_index(train_X_male)\n",
    "\n",
    "valid_X = remove_index(valid_X)\n",
    "valid_X_female = remove_index(valid_X_female)\n",
    "valid_X_male = remove_index(valid_X_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZeroR Baseline > Whole Validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       803\n",
      "           1       0.73      1.00      0.85      2191\n",
      "\n",
      "    accuracy                           0.73      2994\n",
      "   macro avg       0.37      0.50      0.42      2994\n",
      "weighted avg       0.54      0.73      0.62      2994\n",
      "\n",
      "\n",
      "ZeroR Baseline > Female Validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       392\n",
      "           1       0.74      1.00      0.85      1105\n",
      "\n",
      "    accuracy                           0.74      1497\n",
      "   macro avg       0.37      0.50      0.42      1497\n",
      "weighted avg       0.54      0.74      0.63      1497\n",
      "\n",
      "\n",
      "ZeroR Baseline > Male Validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       411\n",
      "           1       0.73      1.00      0.84      1086\n",
      "\n",
      "    accuracy                           0.73      1497\n",
      "   macro avg       0.36      0.50      0.42      1497\n",
      "weighted avg       0.53      0.73      0.61      1497\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"ZeroR Baseline > Whole Validation set\")\n",
    "zero_R_classify(train_X, train_y_true, valid_X, valid_y_true)\n",
    "\n",
    "print(\"ZeroR Baseline > Female Validation set\")\n",
    "zero_R_classify(train_X_female, train_y_true_female,\n",
    "                valid_X_female, valid_y_true_female)\n",
    "\n",
    "print(\"ZeroR Baseline > Male Validation set\")\n",
    "zero_R_classify(train_X_male, train_y_true_male,\n",
    "                valid_X_male, valid_y_true_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN > Whole Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.71      0.62      0.66       803\n",
      "           1       0.87      0.91      0.89      2191\n",
      "\n",
      "    accuracy                           0.83      2994\n",
      "   macro avg       0.79      0.77      0.78      2994\n",
      "weighted avg       0.83      0.83      0.83      2994\n",
      "\n",
      "KNN > Female Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.71      0.64      0.68       392\n",
      "           1       0.88      0.91      0.89      1105\n",
      "\n",
      "    accuracy                           0.84      1497\n",
      "   macro avg       0.79      0.78      0.78      1497\n",
      "weighted avg       0.83      0.84      0.84      1497\n",
      "\n",
      "KNN > Male Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.60      0.67       411\n",
      "           1       0.86      0.92      0.89      1086\n",
      "\n",
      "    accuracy                           0.84      1497\n",
      "   macro avg       0.80      0.76      0.78      1497\n",
      "weighted avg       0.83      0.84      0.83      1497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN > Whole Validation Set\")\n",
    "knn_classify(train_X, train_y_true, valid_X, valid_y_true)\n",
    "\n",
    "print(\"KNN > Female Validation Set\")\n",
    "knn_classify(train_X_female, train_y_true_female,\n",
    "             valid_X_female, valid_y_true_female)\n",
    "\n",
    "print(\"KNN > Male Validation Set\")\n",
    "knn_classify(train_X_male, train_y_true_male, valid_X_male, valid_y_true_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB > Whole Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.70      0.78       803\n",
      "           1       0.90      0.96      0.93      2191\n",
      "\n",
      "    accuracy                           0.89      2994\n",
      "   macro avg       0.88      0.83      0.85      2994\n",
      "weighted avg       0.89      0.89      0.89      2994\n",
      "\n",
      "NB > Female Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.83      0.74      0.78       392\n",
      "           1       0.91      0.94      0.93      1105\n",
      "\n",
      "    accuracy                           0.89      1497\n",
      "   macro avg       0.87      0.84      0.85      1497\n",
      "weighted avg       0.89      0.89      0.89      1497\n",
      "\n",
      "NB > Male Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.67      0.77       411\n",
      "           1       0.89      0.97      0.93      1086\n",
      "\n",
      "    accuracy                           0.89      1497\n",
      "   macro avg       0.89      0.82      0.85      1497\n",
      "weighted avg       0.89      0.89      0.88      1497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"NB > Whole Validation Set\")\n",
    "nb_classify(train_X, train_y_true, valid_X, valid_y_true)\n",
    "\n",
    "print(\"NB > Female Validation Set\")\n",
    "nb_classify(train_X_female, train_y_true_female,\n",
    "            valid_X_female, valid_y_true_female)\n",
    "\n",
    "print(\"NB > Male Validation Set\")\n",
    "nb_classify(train_X_male, train_y_true_male, valid_X_male, valid_y_true_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR > Whole Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.85      0.85       803\n",
      "           1       0.95      0.94      0.94      2191\n",
      "\n",
      "    accuracy                           0.92      2994\n",
      "   macro avg       0.90      0.90      0.90      2994\n",
      "weighted avg       0.92      0.92      0.92      2994\n",
      "\n",
      "LR > Female Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.85      0.84       392\n",
      "           1       0.95      0.94      0.94      1105\n",
      "\n",
      "    accuracy                           0.92      1497\n",
      "   macro avg       0.89      0.90      0.89      1497\n",
      "weighted avg       0.92      0.92      0.92      1497\n",
      "\n",
      "LR > Male Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.81      0.84       411\n",
      "           1       0.93      0.95      0.94      1086\n",
      "\n",
      "    accuracy                           0.92      1497\n",
      "   macro avg       0.90      0.88      0.89      1497\n",
      "weighted avg       0.91      0.92      0.91      1497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"LR > Whole Validation Set\")\n",
    "lr_classify(train_X, train_y_true, valid_X, valid_y_true)\n",
    "\n",
    "print(\"LR > Female Validation Set\")\n",
    "lr_classify(train_X_female, train_y_true_female,\n",
    "            valid_X_female, valid_y_true_female)\n",
    "\n",
    "print(\"LR > Male Validation Set\")\n",
    "lr_classify(train_X_male, train_y_true_male, valid_X_male, valid_y_true_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP > Whole Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.85      0.84       803\n",
      "           1       0.95      0.94      0.94      2191\n",
      "\n",
      "    accuracy                           0.92      2994\n",
      "   macro avg       0.89      0.90      0.89      2994\n",
      "weighted avg       0.92      0.92      0.92      2994\n",
      "\n",
      "MLP > Female Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.85      0.83       392\n",
      "           1       0.95      0.93      0.94      1105\n",
      "\n",
      "    accuracy                           0.91      1497\n",
      "   macro avg       0.88      0.89      0.88      1497\n",
      "weighted avg       0.91      0.91      0.91      1497\n",
      "\n",
      "MLP > Male Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.83      0.83      0.83       411\n",
      "           1       0.93      0.94      0.94      1086\n",
      "\n",
      "    accuracy                           0.91      1497\n",
      "   macro avg       0.88      0.88      0.88      1497\n",
      "weighted avg       0.91      0.91      0.91      1497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"MLP > Whole Validation Set\")\n",
    "mlp_classify(train_X, train_y_true, valid_X, valid_y_true)\n",
    "\n",
    "print(\"MLP > Female Validation Set\")\n",
    "mlp_classify(train_X_female, train_y_true_female,\n",
    "             valid_X_female, valid_y_true_female)\n",
    "\n",
    "print(\"MLP > Male Validation Set\")\n",
    "mlp_classify(train_X_male, train_y_true_male, valid_X_male, valid_y_true_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_class_on_datasets(raw_df, tfidf_df):\n",
    "    pos_comments = raw_df[raw_df[\"rating\"] == 1]\n",
    "    neg_comments = raw_df[raw_df[\"rating\"] == -1]\n",
    "\n",
    "    min_samples = min(len(pos_comments), len(neg_comments))\n",
    "    balanced_pos_samples = pos_comments.sample(n=min_samples, random_state=42)\n",
    "    balanced_neg_samples = neg_comments.sample(n=min_samples, random_state=42)\n",
    "\n",
    "    # Concatenate balanced samples\n",
    "    balanced_raw = pd.concat([balanced_pos_samples, balanced_neg_samples])\n",
    "\n",
    "    # Find corresponding rows in train_X\n",
    "    balanced_X = tfidf_df[tfidf_df.index.isin(balanced_raw.index)]\n",
    "\n",
    "    return balanced_raw, balanced_X\n",
    "\n",
    "\n",
    "# Raw data\n",
    "train_raw = pd.read_csv(\"data/TRAIN.csv\")\n",
    "valid_raw = pd.read_csv(\"data/VALIDATION.csv\")\n",
    "# test_raw = pd.read_csv(\"data/TEST_NO_LABELS.csv\")\n",
    "\n",
    "# TFIDF\n",
    "train_X = pd.read_csv(\"data/TFIDF_TRAIN.csv\")\n",
    "valid_X = pd.read_csv(\"data/TFIDF_VALIDATION.csv\")\n",
    "# test_X = pd.read_csv(\"data/TFIDF_TEST.csv\")\n",
    "\n",
    "# Balances the datasets by gender\n",
    "train_raw, train_X = balance_class_on_datasets(train_raw, train_X)\n",
    "valid_raw, valid_X = balance_class_on_datasets(valid_raw, valid_X)\n",
    "\n",
    "train_raw = train_raw.sort_values(by=\"Unnamed: 0\")\n",
    "train_X = train_X.sort_values(by=\"Unnamed: 0\")\n",
    "valid_raw = valid_raw.sort_values(by=\"Unnamed: 0\")\n",
    "valid_X = valid_X.sort_values(by=\"Unnamed: 0\")\n",
    "\n",
    "# Obtains the true labels\n",
    "train_y_true = train_raw.iloc[:, -1]\n",
    "valid_y_true = valid_raw.iloc[:, -1]\n",
    "\n",
    "# Splits the set by gender\n",
    "train_raw_female, train_raw_male, _ = split_by_gender(train_raw)\n",
    "valid_raw_female, valid_raw_male, _ = split_by_gender(valid_raw)\n",
    "\n",
    "train_y_true_female = train_raw_female.iloc[:, -1]\n",
    "valid_y_true_female = valid_raw_female.iloc[:, -1]\n",
    "train_X_female = train_X[train_raw[\"dr_id_gender\"] == 0]\n",
    "valid_X_female = valid_X[valid_raw[\"dr_id_gender\"] == 0]\n",
    "\n",
    "train_y_true_male = train_raw_male.iloc[:, -1]\n",
    "valid_y_true_male = valid_raw_male.iloc[:, -1]\n",
    "train_X_male = train_X[train_raw[\"dr_id_gender\"] == 1]\n",
    "valid_X_male = valid_X[valid_raw[\"dr_id_gender\"] == 1]\n",
    "\n",
    "train_X = remove_index(train_X)\n",
    "train_X_female = remove_index(train_X_female)\n",
    "train_X_male = remove_index(train_X_male)\n",
    "\n",
    "valid_X = remove_index(valid_X)\n",
    "valid_X_female = remove_index(valid_X_female)\n",
    "valid_X_male = remove_index(valid_X_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZeroR Baseline > Whole Validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.50      1.00      0.67      1462\n",
      "           1       0.00      0.00      0.00      1462\n",
      "\n",
      "    accuracy                           0.50      2924\n",
      "   macro avg       0.25      0.50      0.33      2924\n",
      "weighted avg       0.25      0.50      0.33      2924\n",
      "\n",
      "\n",
      "ZeroR Baseline > Female Validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.48      1.00      0.65       392\n",
      "           1       0.00      0.00      0.00       424\n",
      "\n",
      "    accuracy                           0.48       816\n",
      "   macro avg       0.24      0.50      0.32       816\n",
      "weighted avg       0.23      0.48      0.31       816\n",
      "\n",
      "\n",
      "ZeroR Baseline > Male Validation set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       983\n",
      "           1       0.48      1.00      0.65       914\n",
      "\n",
      "    accuracy                           0.48      1897\n",
      "   macro avg       0.24      0.50      0.33      1897\n",
      "weighted avg       0.23      0.48      0.31      1897\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"ZeroR Baseline > Whole Validation set\")\n",
    "zero_R_classify(train_X, train_y_true, valid_X, valid_y_true)\n",
    "\n",
    "print(\"ZeroR Baseline > Female Validation set\")\n",
    "zero_R_classify(train_X_female, train_y_true_female,\n",
    "                valid_X_female, valid_y_true_female)\n",
    "\n",
    "print(\"ZeroR Baseline > Male Validation set\")\n",
    "zero_R_classify(train_X_male, train_y_true_male,\n",
    "                valid_X_male, valid_y_true_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN > Whole Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.86      0.82      1462\n",
      "           1       0.85      0.77      0.81      1462\n",
      "\n",
      "    accuracy                           0.82      2924\n",
      "   macro avg       0.82      0.82      0.82      2924\n",
      "weighted avg       0.82      0.82      0.82      2924\n",
      "\n",
      "KNN > Female Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.87      0.83       392\n",
      "           1       0.87      0.78      0.82       424\n",
      "\n",
      "    accuracy                           0.82       816\n",
      "   macro avg       0.83      0.83      0.82       816\n",
      "weighted avg       0.83      0.82      0.82       816\n",
      "\n",
      "KNN > Male Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.86      0.83       983\n",
      "           1       0.84      0.79      0.81       914\n",
      "\n",
      "    accuracy                           0.82      1897\n",
      "   macro avg       0.83      0.82      0.82      1897\n",
      "weighted avg       0.82      0.82      0.82      1897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN > Whole Validation Set\")\n",
    "knn_classify(train_X, train_y_true, valid_X, valid_y_true)\n",
    "\n",
    "print(\"KNN > Female Validation Set\")\n",
    "knn_classify(train_X_female, train_y_true_female,\n",
    "             valid_X_female, valid_y_true_female)\n",
    "\n",
    "print(\"KNN > Male Validation Set\")\n",
    "knn_classify(train_X_male, train_y_true_male, valid_X_male, valid_y_true_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB > Whole Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.91      0.88      1462\n",
      "           1       0.90      0.85      0.88      1462\n",
      "\n",
      "    accuracy                           0.88      2924\n",
      "   macro avg       0.88      0.88      0.88      2924\n",
      "weighted avg       0.88      0.88      0.88      2924\n",
      "\n",
      "NB > Female Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.93      0.89       392\n",
      "           1       0.93      0.86      0.89       424\n",
      "\n",
      "    accuracy                           0.89       816\n",
      "   macro avg       0.89      0.89      0.89       816\n",
      "weighted avg       0.89      0.89      0.89       816\n",
      "\n",
      "NB > Male Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.84      0.87       983\n",
      "           1       0.84      0.89      0.87       914\n",
      "\n",
      "    accuracy                           0.87      1897\n",
      "   macro avg       0.87      0.87      0.87      1897\n",
      "weighted avg       0.87      0.87      0.87      1897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"NB > Whole Validation Set\")\n",
    "nb_classify(train_X, train_y_true, valid_X, valid_y_true)\n",
    "\n",
    "print(\"NB > Female Validation Set\")\n",
    "nb_classify(train_X_female, train_y_true_female,\n",
    "            valid_X_female, valid_y_true_female)\n",
    "\n",
    "print(\"NB > Male Validation Set\")\n",
    "nb_classify(train_X_male, train_y_true_male, valid_X_male, valid_y_true_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR > Whole Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.92      0.90      1462\n",
      "           1       0.92      0.88      0.90      1462\n",
      "\n",
      "    accuracy                           0.90      2924\n",
      "   macro avg       0.90      0.90      0.90      2924\n",
      "weighted avg       0.90      0.90      0.90      2924\n",
      "\n",
      "LR > Female Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.93      0.91       392\n",
      "           1       0.93      0.89      0.91       424\n",
      "\n",
      "    accuracy                           0.91       816\n",
      "   macro avg       0.91      0.91      0.91       816\n",
      "weighted avg       0.91      0.91      0.91       816\n",
      "\n",
      "LR > Male Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.92      0.91       983\n",
      "           1       0.91      0.88      0.90       914\n",
      "\n",
      "    accuracy                           0.90      1897\n",
      "   macro avg       0.90      0.90      0.90      1897\n",
      "weighted avg       0.90      0.90      0.90      1897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"LR > Whole Validation Set\")\n",
    "lr_classify(train_X, train_y_true, valid_X, valid_y_true)\n",
    "\n",
    "print(\"LR > Female Validation Set\")\n",
    "lr_classify(train_X_female, train_y_true_female,\n",
    "            valid_X_female, valid_y_true_female)\n",
    "\n",
    "print(\"LR > Male Validation Set\")\n",
    "lr_classify(train_X_male, train_y_true_male, valid_X_male, valid_y_true_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP > Whole Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.92      0.90      1462\n",
      "           1       0.92      0.88      0.90      1462\n",
      "\n",
      "    accuracy                           0.90      2924\n",
      "   macro avg       0.90      0.90      0.90      2924\n",
      "weighted avg       0.90      0.90      0.90      2924\n",
      "\n",
      "MLP > Female Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.92      0.91       392\n",
      "           1       0.93      0.89      0.91       424\n",
      "\n",
      "    accuracy                           0.91       816\n",
      "   macro avg       0.91      0.91      0.91       816\n",
      "weighted avg       0.91      0.91      0.91       816\n",
      "\n",
      "MLP > Male Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.91      0.90       983\n",
      "           1       0.91      0.89      0.90       914\n",
      "\n",
      "    accuracy                           0.90      1897\n",
      "   macro avg       0.90      0.90      0.90      1897\n",
      "weighted avg       0.90      0.90      0.90      1897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"MLP > Whole Validation Set\")\n",
    "mlp_classify(train_X, train_y_true, valid_X, valid_y_true)\n",
    "\n",
    "print(\"MLP > Female Validation Set\")\n",
    "mlp_classify(train_X_female, train_y_true_female,\n",
    "             valid_X_female, valid_y_true_female)\n",
    "\n",
    "print(\"MLP > Male Validation Set\")\n",
    "mlp_classify(train_X_male, train_y_true_male, valid_X_male, valid_y_true_male)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
